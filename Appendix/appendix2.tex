
\section{Literature Review of Base Paper- I}
\onehalfspacing

\begin{table}[H]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{p{8.69cm}p{0.07cm}p{7.98cm}p{0.07cm}}
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Author(s)/Source: } Ghada Alhussein, Ioannis Ziogas, Shiza Saleem, Leontios J. Hadjileontiadis }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Title: } Voice emotion recognition in conversations using artificial intelligence: a systematic review and meta-analysis }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Website: \url{https://doi.org/10.1007/s10462-025-11197-8}}}} \\ 
\hline
\multicolumn{2}{|p{8.76cm}}{{ \textbf{Publication Date: } 2025 }} & 
\multicolumn{2}{|p{8.05cm}|}{{ \textbf{Access Date: } November, 2025 }} \\ 
\hline
\multicolumn{2}{|p{8.76cm}}{{ \textbf{Publisher/Journal: } Artificial Intelligence Review }} & 
\multicolumn{2}{|p{8.05cm}|}{{ \textbf{Place: } n/a }} \\ 
\hline
\multicolumn{2}{|p{8.76cm}}{{ \textbf{Volume: } 58 }} & 
\multicolumn{2}{|p{8.05cm}|}{{ \textbf{Issue Number: } n/a }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Author's position/theoretical position: } Researchers performed a systematic review and meta-analysis to evaluate models and datasets for emotion recognition in conversation, focusing on multimodal and dimensional approaches. }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Keywords: } voice Emotion Recognition, Emotion Recognition in Conversation, Systematic Review, Meta-Analysis, PRISMA-DTA, IEMOCAP, MELD, K-EmoCon, CNN, RNN, LSTM, Transformer }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{\underline{Important points, notes, quotations } \hfill \underline{Page No.}} }
\begin{enumerate}
    \vspace{-0.2cm} \item 51 studies reviewed systematically, 27 included in meta-analysis. \hfill \textbf{2}
    \vspace{-0.5cm} \item IEMOCAP most widely used, followed by MELD and K-EmoCon databases. \hfill \textbf{3}
    \vspace{-0.5cm} \item Models include CNN, RNN, LSTM, and Transformer networks. \hfill \textbf{4}
    \vspace{-0.5cm} \item Both categorical and dimensional approaches examined for emotion recognition. \hfill \textbf{5}
    \vspace{-0.5cm} \item High heterogeneity observed across studies, concerns about annotation quality noted. \hfill \textbf{6}
    \vspace{-0.5cm} \item Multimodal approaches integrating audio, visual, and textual features improve performance. \hfill \textbf{7}
    \vspace{-0.5cm} \item Limitation: inconsistent evaluation metrics across studies. \hfill \textbf{8}
    \vspace{-0.5cm} \item Future work: standardized datasets and evaluation protocols recommended. \hfill \textbf{9}
\end{enumerate}
} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Essential Background Information: } Emotion recognition in conversation is critical for human-computer interaction, dialogue systems, and virtual assistants. Systematic review ensures comprehensive understanding of existing methods, datasets, and model performance, highlighting gaps in consistency and annotation quality. }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Overall argument or hypothesis: } Current ERC models vary widely, and systematic evaluation can reveal effective approaches and gaps for improving multimodal emotion recognition. }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Conclusion: } Systematic review identifies strengths and weaknesses in ERC models, recommends standardization, and highlights promising deep learning and multimodal approaches for future research. }} \\ 
\hline
\multicolumn{1}{|p{9.69cm}}{{ \textbf{Supporting Reasons}}} & 
\multicolumn{2}{p{8.05cm}|}{} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 1. Comprehensive dataset coverage in studies. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 2. Use of CNN, RNN, LSTM, Transformer models captures temporal dependencies. }} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 3. Multimodal approaches improve recognition accuracy. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 4. PRISMA-DTA ensures systematic review reliability. }} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 5. Meta-analysis quantifies model performance. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 6. Identifies limitations in current datasets. }} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 7. Highlights need for standardized evaluation. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 8. Future work encourages reproducibility and multimodal integration. }} \\ 
\hline
\multicolumn{3}{|p{16.74cm}|}{{ \textbf{Strengths of the line of reasoning and supporting evidence: } Systematic methodology, large number of studies, comprehensive analysis of models and datasets, clear identification of gaps, emphasis on multimodal approaches, practical guidance for future research. }} \\ 
\hline
\multicolumn{3}{|p{16.74cm}|}{{ \textbf{Flaws in the argument and gaps or other weaknesses: } Variability in datasets, inconsistent metrics, heterogeneity in model performance, annotation quality not always reliable, results may not generalize across languages. }} \\ 
\hline
\end{tabular}
\end{adjustbox}
\end{table}
