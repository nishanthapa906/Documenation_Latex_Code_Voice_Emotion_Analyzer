
\section{Literature Review of Base Paper- VII}
\onehalfspacing

\begin{table}[H]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{p{8.69cm}p{0.07cm}p{7.98cm}p{0.07cm}}
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Author(s)/Source: } Christiana Tsiourti, Astrid Weiss, Katarzyna Wac, Markus Vincze }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Title: } Multimodal Integration of Emotional Signals from Voice, Body, and Context: Effects of (In)Congruence on Emotion Recognition and Attitudes Towards Robots }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Website: } \url{https://link.springer.com/article/10.1007/s12369-019-00538-5} }} \\ 
\hline
\multicolumn{2}{|p{8.76cm}}{{ \textbf{Publication Date: } 2019 }} & 
\multicolumn{2}{|p{8.05cm}|}{{ \textbf{Access Date: }  }} \\ 
\hline
\multicolumn{2}{|p{8.76cm}}{{ \textbf{Publisher/Journal: } International Journal of Social Robotics }} & 
\multicolumn{2}{|p{8.05cm}|}{{ \textbf{Place: } Germany }} \\ 
\hline
\multicolumn{2}{|p{8.76cm}}{{ \textbf{Volume: } 11 }} & 
\multicolumn{2}{|p{8.05cm}|}{{ \textbf{Issue Number: } 4 }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Author's position/theoretical position: } The authors focus on multimodal emotion recognition for social robots. They emphasize integrating voice, body gestures, and contextual cues to improve emotion understanding and human attitudes towards robotic systems. }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Keywords: } Multimodal Emotion Recognition, Voice Signals, Body Language, Context Awareness, Social Robots, Human Robot Interaction }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{\underline{Important points, notes, quotations } \hfill \underline{Page No.}} }
\begin{enumerate}
    \vspace{-0.2cm} \item Emotional signals collected from voice, body posture, and situational context. \hfill \textbf{556}
    \vspace{-0.5cm} \item Study examines congruent and incongruent emotional cues. \hfill \textbf{558}
    \vspace{-0.5cm} \item Multimodal integration improves emotion recognition accuracy. \hfill \textbf{560}
    \vspace{-0.5cm} \item Voice remains a strong indicator of emotional state. \hfill \textbf{561}
    \vspace{-0.5cm} \item Incongruence affects user trust and perception of robots. \hfill \textbf{563}
    \vspace{-0.5cm} \item Human attitudes are influenced by emotional consistency. \hfill \textbf{565}
    \vspace{-0.5cm} \item Results support multimodal fusion strategies. \hfill \textbf{567}
    \vspace{-0.5cm} \item Application relevance for social and assistive robots. \hfill \textbf{570}
\end{enumerate}
} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Essential Background Information: } Emotion recognition in robots benefits from combining multiple modalities. Voice, body language, and contextual cues together provide richer emotional understanding than unimodal systems. }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Overall argument or hypothesis: } Multimodal emotion integration enhances recognition accuracy and positively influences human attitudes towards robots, especially when emotional cues are congruent. }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Conclusion: } The study confirms that multimodal emotion recognition significantly improves robot perception and interaction quality. Emotional congruence plays a vital role in trust and acceptance. }} \\ 
\hline
\multicolumn{1}{|p{9.69cm}}{{ \textbf{Supporting Reasons}}} & 
\multicolumn{2}{p{8.05cm}|}{} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 1. Voice provides strong emotional cues. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 2. Body language enhances emotion interpretation. }} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 3. Context improves emotional accuracy. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 4. Congruence increases user trust. }} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 5. Multimodal fusion outperforms unimodal methods. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 6. Improves social robot interaction quality. }} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 7. Supports assistive robot applications. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 8. Enhances human robot engagement. }} \\ 
\hline
\multicolumn{3}{|p{16.74cm}|}{{ \textbf{Strengths of the line of reasoning and supporting evidence: } Multimodal analysis, strong experimental validation, relevance to social robotics, comprehensive evaluation of congruence effects, and human centered design focus. }} \\ 
\hline
\multicolumn{3}{|p{16.74cm}|}{{ \textbf{Flaws in the argument and gaps or other weaknesses: } Experimental setting controlled, limited real world deployment, complexity of multimodal systems, and increased computational requirements. }} \\ 
\hline
\end{tabular}
\end{adjustbox}
\end{table}
