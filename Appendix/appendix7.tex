


\section{Literature Review of Base Paper- VI}
\onehalfspacing

\begin{table}[H]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{p{8.69cm}p{0.07cm}p{7.98cm}p{0.07cm}}
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Author(s)/Source: } A. Hassan, R. Damper }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Title: } End-to-End voice Emotion Recognition Using Deep Convolutional Neural Networks }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Website: } \url{https://ieeexplore.ieee.org/document/9432061} }} \\ 
\hline
\multicolumn{2}{|p{8.76cm}}{{ \textbf{Publication Date: } 2021 }} & 
\multicolumn{2}{|p{8.05cm}|}{{ \textbf{Access Date: } November, 2022 }} \\ 
\hline
\multicolumn{2}{|p{8.76cm}}{{ \textbf{Publisher/Journal: } IEEE Access }} & 
\multicolumn{2}{|p{8.05cm}|}{{ \textbf{Place: } United Kingdom }} \\ 
\hline
\multicolumn{2}{|p{8.76cm}}{{ \textbf{Volume: } 9 }} & 
\multicolumn{2}{|p{8.05cm}|}{{ \textbf{Issue Number: } - }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Author's position/theoretical position: } Researchers emphasize that end-to-end deep learning models, specifically Convolutional Neural Networks, can learn emotional features directly from voice without manual feature extraction. }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Keywords: } voice Emotion Recognition, CNN, End-to-End Learning, Spectrogram, Deep Learning, Feature Extraction, Audio Classification, Human-Computer Interaction }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{\underline{Important points, notes, quotations } \hfill \underline{Page No.}} }
\begin{enumerate}
    \vspace{-0.2cm} \item CNN model trained directly on spectrograms of voice signals for emotion classification. \hfill \textbf{3}
    \vspace{-0.5cm} \item Achieved accuracy: 83.7\% on RAVDESS and 81.4\% on EMO-DB datasets. \hfill \textbf{4}
    \vspace{-0.5cm} \item Model includes multiple convolutional and pooling layers followed by dense classification layers. \hfill \textbf{5}
    \vspace{-0.5cm} \item Batch normalization and dropout layers used to prevent overfitting and stabilize training. \hfill \textbf{6}
    \vspace{-0.5cm} \item The CNN extracts emotional cues automatically, removing the need for handcrafted features like MFCC. \hfill \textbf{7}
    \vspace{-0.5cm} \item End-to-end system simplifies preprocessing and is adaptable to multiple datasets. \hfill \textbf{8}
    \vspace{-0.5cm} \item Real-time implementation feasible with GPU acceleration. \hfill \textbf{9}
    \vspace{-0.5cm} \item Limitation: requires large labeled datasets and high computation for training. \hfill \textbf{10}
\end{enumerate}
} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Essential Background Information: } Traditional systems depend heavily on feature engineering methods like MFCC, Chroma, and pitch. In contrast, end-to-end CNN architectures learn meaningful emotional features directly from spectrograms. }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Overall argument or hypothesis: } CNN-based end-to-end emotion recognition outperforms traditional handcrafted methods by learning robust and transferable features directly from raw voice data, enhancing emotion-aware applications. }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Conclusion: } Deep CNN models eliminate the need for complex preprocessing and achieve strong accuracy across multiple datasets. They provide a scalable and efficient framework for real-time voice emotion recognition applications. }} \\ 
\hline
\multicolumn{1}{|p{9.69cm}}{{ \textbf{Supporting Reasons}}} & 
\multicolumn{2}{p{8.05cm}|}{} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 1. CNN automatically extracts emotional features from spectrograms. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 2. Batch normalization ensures stable convergence. }} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 3. GPU acceleration supports real-time use. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 4. CNN model generalizes well to different datasets. }} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 5. End-to-end design reduces human intervention. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 6. Deep layers capture complex emotional dependencies. }} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 7. Outperforms traditional models like SVM and MLP. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 8. Future work involves data augmentation and multilingual testing. }} \\ 
\hline
\multicolumn{3}{|p{16.74cm}|}{{ \textbf{Strengths of the line of reasoning and supporting evidence: } High accuracy, real-time feasibility, reduced feature dependency. }} \\ 
\hline
\multicolumn{3}{|p{16.74cm}|}{{ \textbf{Flaws in the argument and gaps or other weaknesses: } High computational demand, limited interpretability. }} \\ 
\hline
\end{tabular}
\end{adjustbox}
\end{table}









