
\section{Literature Review of Base Paper- III}
\onehalfspacing

\begin{table}[H]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{p{8.69cm}p{0.07cm}p{7.98cm}p{0.07cm}}
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Author(s)/Source: } Rohit Rastogi, Tushar Anand, Shubham Kumar Sharma, Sarthak Panwar }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Title: } Emotion Detection via Voice and voice Recognition }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Website: \url{https://doi.org/10.4018/IJCBPL.333473}}}} \\ 
\hline
\multicolumn{2}{|p{8.76cm}}{{ \textbf{Publication Date: } 2023 }} & 
\multicolumn{2}{|p{8.05cm}|}{{ \textbf{Access Date: } November, 2025 }} \\ 
\hline
\multicolumn{2}{|p{8.76cm}}{{ \textbf{Publisher/Journal: } International Journal of Cyber Behavior, Psychology and Learning }} & 
\multicolumn{2}{|p{8.05cm}|}{{ \textbf{Place: } n/a }} \\ 
\hline
\multicolumn{2}{|p{8.76cm}}{{ \textbf{Volume: } 13 }} & 
\multicolumn{2}{|p{8.05cm}|}{{ \textbf{Issue Number: } 1 }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Author's position/theoretical position: } Researchers in SER focused on developing machine learning models for emotion recognition from voice to improve Human-Computer Interaction. }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Keywords: } voice Emotion Recognition, MLP Classifier, MFCC, Librosa, RAVDESS, Human-Computer Interaction, Emotional voice Dataset, Audio Feature Extraction }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{\underline{Important points, notes, quotations } \hfill \underline{Page No.}} }
\begin{enumerate}
    \vspace{-0.2cm} \item The RAVDESS dataset contains 7356 audio files from 24 professional actors covering eight emotions: neutral, calm, happy, sad, angry, fearful, disgust, surprised. \hfill \textbf{5}
    \vspace{-0.5cm} \item MFCC features were extracted using Librosa to represent the spectral characteristics of audio for SER. \hfill \textbf{6}
    \vspace{-0.5cm} \item MLP classifier trained on MFCC features achieved 75\% accuracy for eight emotions. \hfill \textbf{7}
    \vspace{-0.5cm} \item Data preprocessing included noise reduction, normalization, and dataset splitting. \hfill \textbf{8}
    \vspace{-0.5cm} \item SER application enhances Human-Computer Interaction by detecting emotions in real-time. \hfill \textbf{9}
    \vspace{-0.5cm} \item Comparison with SVM and Random Forest classifiers showed MLP was computationally efficient with reasonable accuracy. \hfill \textbf{10}
    \vspace{-0.5cm} \item Limitations: English-only dataset and potential overfitting due to dataset size. \hfill \textbf{11}
    \vspace{-0.5cm} \item Future work: integrating CNN/RNN models and multilingual datasets. \hfill \textbf{12}
\end{enumerate}
} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Essential Background Information: } voice Emotion Recognition (SER) is critical for virtual assistants, intelligent tutoring, and mental health monitoring. Accurate SER depends on robust feature extraction and effective classifiers. MFCC represents audio signals, and MLPs are efficient for multi-class classification. Many studies have limited datasets, showing the need for more evaluation. }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Overall argument or hypothesis: } Using MFCC features with an MLP classifier on RAVDESS data enables reliable detection of eight discrete emotions, bridging the gap between audio and emotional understanding in Human-Computer Interaction. }} \\ 
\hline
\multicolumn{4}{|p{16.82cm}|}{{ \textbf{Conclusion: } MLP-based SER systems using MFCC features achieve reasonable accuracy, demonstrating practical applications. Future work should address multilingual datasets and deep learning methods. }} \\ 
\hline
\multicolumn{1}{|p{9.69cm}}{{ \textbf{Supporting Reasons}}} & 
\multicolumn{2}{p{8.05cm}|}{} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 1. RAVDESS dataset provides diverse emotional audio samples. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 2. MLP classifier balances accuracy and computational efficiency. }} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 3. MFCC captures spectral nuances critical for emotion recognition. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 4. Focus on HCI ensures practical relevance. }} \\ 
\hhline{~~~}
\multicolumn{1}{|p{8.69cm}}{{ 5. Comparison with other classifiers shows MLP superiority. }} & 
\multicolumn{2}{p{8.05cm}|}{{ 6. Future work supports scalability to multilingual datasets and deep learning models. }} \\ 
\hline
\multicolumn{3}{|p{16.74cm}|}{{ \textbf{Strengths of the line of reasoning and supporting evidence: } Clear experimental design, standardized dataset, reproducible results, practical HCI applications, effective feature extraction and classifier choice, comparative analysis with other methods. }} \\ 
\hline
\multicolumn{3}{|p{16.74cm}|}{{ \textbf{Flaws in the argument and gaps or other weaknesses: } Limited to English, dataset moderate in size, 75\% accuracy. }} \\ 
\hline
\end{tabular}
\end{adjustbox}
\end{table}




